{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366d6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import time\n",
    "from ib_async import IB, Stock\n",
    "from ib_async import IB, ScannerSubscription\n",
    "from ib_async import IB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc5bef6",
   "metadata": {},
   "source": [
    "### VALUE & QUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c0b822-574a-45d2-bd2f-cbc90a2023c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics and parameters for Value and Quality Factors defined.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define Metrics and Parameters\n",
    "# Description: Define the value and quality metrics for stock screening, incorporating industry medians, historical ranges, or both.\n",
    "\n",
    "# Value Metrics\n",
    "value_metrics = {\n",
    "    # Dual Benchmarking: Industry Median + Historical Range\n",
    "    'P/E': {\n",
    "        'benchmark': {\n",
    "            'industry_median': 'below_median',\n",
    "            'historical_percentile': '<50th'  # Below the 5-year historical median\n",
    "        },\n",
    "        'target': 'below both benchmarks'  # Must meet both conditions\n",
    "    },\n",
    "    # Dual Benchmarking: Industry Median + Historical Range\n",
    "    'P/FCF': {\n",
    "        'benchmark': {\n",
    "            'industry_median': 'below_median',\n",
    "            'historical_range': '<50th'  # Below historical range (inverse high FCF Yield)\n",
    "        },\n",
    "        'target': 'below both benchmarks'\n",
    "    },\n",
    "    # Industry Median + Growth-Adjusted Benchmark\n",
    "    'EV/EBITDA': {\n",
    "        'benchmark': {\n",
    "            'industry_median': '<1.5',  # EV/EBITDA less than 1.5x industry median\n",
    "            'historical_range': '<50th'  # Below 50th percentile of historical EV/EBITDA\n",
    "        },\n",
    "        'target': 'below both benchmarks'\n",
    "    },\n",
    "    # PEG Ratio: Company-Specific Target (Requires Earnings Growth Rate)\n",
    "    'PEG': {\n",
    "        'benchmark': None,  # Evaluated directly against a fixed target\n",
    "        'target': '<1'  # Undervalued relative to growth\n",
    "    }\n",
    "}\n",
    "\n",
    "# Quality Metrics\n",
    "quality_metrics = {\n",
    "    # Dual Benchmarking: Industry Median + Historical Stability\n",
    "    'ROE': {\n",
    "        'benchmark': {\n",
    "            'industry_median': '>15%',\n",
    "            'historical_stability': 'consistent'  # Stable ROE trends over time\n",
    "        },\n",
    "        'target': 'meets both benchmarks'\n",
    "    },\n",
    "    # Industry Median Only\n",
    "    'FCF Yield': {\n",
    "        'benchmark': {\n",
    "            'industry_median': 'above_median'  # Stronger than peers\n",
    "        },\n",
    "        'target': 'above benchmark'\n",
    "    },\n",
    "    # Historical Growth Comparison (Requires Historical EBITDA Data)\n",
    "    'EBITDA Growth': {\n",
    "        'benchmark': {\n",
    "            'historical_cagr': 'above_median'  # CAGR greater than historical median\n",
    "        },\n",
    "        'target': 'meets benchmark'\n",
    "    },\n",
    "    # Historical Stability Only (Requires Historical Revenue Data)\n",
    "    'Revenue Growth Stability': {\n",
    "        'benchmark': {\n",
    "            'historical_stability': 'consistent YoY growth'  # Year-over-Year stability\n",
    "        },\n",
    "        'target': 'meets benchmark'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print Confirmation\n",
    "print(\"Metrics and parameters for Value and Quality Factors defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c16027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock universe includes 604 stocks.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch Stock Universe\n",
    "# S&P 500 Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "table_sp = pd.read_html(url)\n",
    "sp500_table = table_sp[0]\n",
    "\n",
    "sp500_tickers = sp500_table['Symbol'].tolist() # List of Tickers\n",
    "   \n",
    "# NASDAQ-100 Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/NASDAQ-100'\n",
    "tables_nas = pd.read_html(url)\n",
    "nasdaq_table = tables_nas[4]\n",
    "nasdaq_tickers = nasdaq_table['Symbol'].tolist()  # List of Tickers\n",
    "\n",
    "# Stock Universe\n",
    "stock_universe = sp500_tickers + nasdaq_tickers\n",
    "print(f\"Stock universe includes {len(stock_universe)} stocks.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48976c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Duplicates\n",
    "stock_universe = list(set(stock_universe))\n",
    "len(stock_universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f70b5d-2502-4fcd-8f59-69c5322c1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch Historical Data with Batching and Sleep\n",
    "def fetch_historical_data(stock_list, batch_size=50, delay=1):\n",
    "    print(\"Fetching historical data in batches...\")\n",
    "    historical_data = {}\n",
    "    \n",
    "    # Process the stock list in batches\n",
    "    for i in range(0, len(stock_list), batch_size):\n",
    "        batch = stock_list[i:i + batch_size]  # Get the current batch\n",
    "        print(f\"Processing batch {i // batch_size + 1} ({len(batch)} stocks)...\")\n",
    "        \n",
    "        for symbol in batch:\n",
    "            try:\n",
    "                ticker = yf.Ticker(symbol)\n",
    "                hist = ticker.history(period=\"max\")\n",
    "                financials = ticker.financials\n",
    "\n",
    "                # Fetch raw data without calculations\n",
    "                revenue = financials.loc['Total Revenue', :] if 'Total Revenue' in financials.index else None\n",
    "                ebitda = financials.loc['EBITDA', :] if 'EBITDA' in financials.index else None\n",
    "\n",
    "                historical_data[symbol] = {\n",
    "                    \"price_median\": hist['Close'].median() if not hist.empty else np.nan,\n",
    "                    \"price_50th_percentile\": np.percentile(hist['Close'], 50) if not hist.empty else np.nan,\n",
    "                    \"revenue\": revenue,\n",
    "                    \"ebitda\": ebitda,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching historical data for {symbol}: {e}\")\n",
    "            \n",
    "            time.sleep(delay)  # Pause to avoid rate-limiting\n",
    "            \n",
    "    return pd.DataFrame.from_dict(historical_data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcb8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch Fundamental Data with Batching and Sleep\n",
    "def fetch_fundamental_data(stock_list, batch_size=50, delay=1):\n",
    "    print(\"Fetching fundamental data in batches...\")\n",
    "    fundamental_data = {}\n",
    "    \n",
    "    # Process the stock list in batches\n",
    "    for i in range(0, len(stock_list), batch_size):\n",
    "        batch = stock_list[i:i + batch_size]  # Get the current batch\n",
    "        print(f\"Processing batch {i // batch_size + 1} ({len(batch)} stocks)...\")\n",
    "        \n",
    "        for symbol in batch:\n",
    "            try:\n",
    "                ticker = yf.Ticker(symbol)\n",
    "                info = ticker.info\n",
    "\n",
    "                fundamental_data[symbol] = {\n",
    "                    \"forwardPE\": info.get(\"forwardPE\"),\n",
    "                    \"trailingPE\": info.get(\"trailingPE\"),\n",
    "                    \"enterpriseValue\": info.get(\"enterpriseValue\"),\n",
    "                    \"freeCashflow\": info.get(\"freeCashflow\"),\n",
    "                    \"returnOnEquity\": info.get(\"returnOnEquity\"),\n",
    "                    \"operatingCashflow\": info.get(\"operatingCashflow\"),\n",
    "                    \"currentPrice\": info.get(\"currentPrice\"),\n",
    "                    \"industry\": info.get(\"industry\"),\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching fundamental data for {symbol}: {e}\")\n",
    "            \n",
    "            time.sleep(delay)  # Pause to avoid rate-limiting\n",
    "    \n",
    "    return pd.DataFrame.from_dict(fundamental_data, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872700f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching historical data in batches...\n",
      "Processing batch 1 (50 stocks)...\n",
      "Processing batch 2 (50 stocks)...\n",
      "Processing batch 3 (50 stocks)...\n",
      "Processing batch 4 (50 stocks)...\n",
      "Processing batch 5 (50 stocks)...\n",
      "Processing batch 6 (50 stocks)...\n",
      "Processing batch 7 (50 stocks)...\n",
      "Processing batch 8 (50 stocks)...\n",
      "Processing batch 9 (50 stocks)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BF.B: possibly delisted; no price data found  (1d 1925-12-24 -> 2024-11-29)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 10 (50 stocks)...\n",
      "Processing batch 11 (20 stocks)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRK.B: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching fundamental data in batches...\n",
      "Processing batch 1 (50 stocks)...\n",
      "Processing batch 2 (50 stocks)...\n",
      "Processing batch 3 (50 stocks)...\n",
      "Processing batch 4 (50 stocks)...\n",
      "Processing batch 5 (50 stocks)...\n",
      "Processing batch 6 (50 stocks)...\n",
      "Processing batch 7 (50 stocks)...\n",
      "Processing batch 8 (50 stocks)...\n",
      "Processing batch 9 (50 stocks)...\n",
      "Processing batch 10 (50 stocks)...\n",
      "Processing batch 11 (20 stocks)...\n",
      "\n",
      "Historical Data Summary:\n",
      "      price_median  price_50th_percentile  \\\n",
      "MU       12.987206              12.987206   \n",
      "BRO       6.252452               6.252452   \n",
      "ITW      17.168869              17.168869   \n",
      "FTNT      8.013000               8.013000   \n",
      "NTRS     28.407188              28.407188   \n",
      "\n",
      "                                                revenue  \\\n",
      "MU    2024-08-31    25111000000.0\n",
      "2023-08-31    1554...   \n",
      "BRO   2023-12-31    4199400000.0\n",
      "2022-12-31    35632...   \n",
      "ITW   2023-12-31    16107000000.0\n",
      "2022-12-31    1593...   \n",
      "FTNT  2023-12-31    5304800000.0\n",
      "2022-12-31    44174...   \n",
      "NTRS  2023-12-31    6773500000.0\n",
      "2022-12-31    67612...   \n",
      "\n",
      "                                                 ebitda  \n",
      "MU    2024-08-31     9582000000.0\n",
      "2023-08-31     248...  \n",
      "BRO   2023-12-31    1549800000.0\n",
      "2022-12-31    12101...  \n",
      "ITW   2023-12-31    4484000000.0\n",
      "2022-12-31    44550...  \n",
      "FTNT  2023-12-31    1468100000.0\n",
      "2022-12-31    10778...  \n",
      "NTRS                                               None  \n",
      "\n",
      "Fundamental Data Summary:\n",
      "      forwardPE trailingPE  enterpriseValue  freeCashflow  returnOnEquity  \\\n",
      "MU     7.635285   140.2857     1.148505e+11  3.635000e+08         0.01743   \n",
      "BRO   27.675028  30.844685     3.523649e+10  7.605125e+08         0.18144   \n",
      "ITW   25.650415  23.920279     8.891461e+10  2.560000e+09         1.08036   \n",
      "FTNT  38.922615   47.26633     6.946874e+10  1.648400e+09         3.11525   \n",
      "NTRS  14.393873  13.772104     3.058718e+10           NaN         0.13732   \n",
      "\n",
      "      operatingCashflow  currentPrice                        industry  \n",
      "MU         8.507000e+09         98.20                  Semiconductors  \n",
      "BRO        1.118500e+09        113.20               Insurance Brokers  \n",
      "ITW        3.206000e+09        276.04  Specialty Industrial Machinery  \n",
      "FTNT       1.972200e+09         94.06       Software - Infrastructure  \n",
      "NTRS       4.952000e+09        110.59                Asset Management  \n"
     ]
    }
   ],
   "source": [
    "# Main Execution: Fetching Data\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 50  # Number of stocks per batch\n",
    "    delay = 1        # Seconds to wait between requests\n",
    "    \n",
    "    # Fetch historical and fundamental data\n",
    "    historical_data = fetch_historical_data(stock_universe, batch_size=batch_size, delay=delay)\n",
    "    fundamental_data = fetch_fundamental_data(stock_universe, batch_size=batch_size, delay=delay)\n",
    "\n",
    "    # Display fetched data summaries\n",
    "    print(\"\\nHistorical Data Summary:\")\n",
    "    print(historical_data.head())\n",
    "\n",
    "    print(\"\\nFundamental Data Summary:\")\n",
    "    print(fundamental_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc288975-c2db-4f15-8913-0c7114c5054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate Metrics\n",
    "def calculate_metrics(historical_data, fundamental_data):\n",
    "    print(\"Calculating metrics based on methodology...\")\n",
    "    results = fundamental_data.copy()\n",
    "\n",
    "    # Ensure numerical consistency\n",
    "    numeric_columns = ['forwardPE', 'trailingPE', 'enterpriseValue', \n",
    "                       'freeCashflow', 'returnOnEquity', 'operatingCashflow']\n",
    "    results[numeric_columns] = results[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Revenue and EBITDA growth calculations\n",
    "    growth_metrics = {}\n",
    "    for symbol in historical_data.index:\n",
    "        try:\n",
    "            revenue = historical_data.loc[symbol, 'revenue']\n",
    "            ebitda = historical_data.loc[symbol, 'ebitda']\n",
    "\n",
    "            # Explicitly handle missing values and enforce float type\n",
    "            if revenue is not None:\n",
    "                revenue = revenue.dropna()\n",
    "                revenue_growth = revenue.pct_change().mean() * 100\n",
    "                revenue_growth = float(revenue_growth)  # Ensure float type\n",
    "            else:\n",
    "                revenue_growth = np.nan\n",
    "\n",
    "            if ebitda is not None:\n",
    "                ebitda = ebitda.dropna()\n",
    "                ebitda_growth = ebitda.pct_change().mean() * 100\n",
    "                ebitda_growth = float(ebitda_growth)  # Ensure float type\n",
    "            else:\n",
    "                ebitda_growth = np.nan\n",
    "\n",
    "            growth_metrics[symbol] = {\n",
    "                \"revenue_growth\": revenue_growth,\n",
    "                \"ebitda_growth\": ebitda_growth,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating growth metrics for {symbol}: {e}\")\n",
    "            growth_metrics[symbol] = {\"revenue_growth\": np.nan, \"ebitda_growth\": np.nan}\n",
    "    \n",
    "    growth_df = pd.DataFrame.from_dict(growth_metrics, orient='index')\n",
    "    results = results.merge(growth_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # Industry-level benchmarks\n",
    "    industry_medians = (\n",
    "        results.groupby(\"industry\")[[\"forwardPE\", \"enterpriseValue\", \"freeCashflow\", \"returnOnEquity\"]]\n",
    "        .median()\n",
    "        .add_suffix(\"_industry_median\")\n",
    "    )\n",
    "    results = results.merge(industry_medians, left_on=\"industry\", right_index=True, how=\"left\")\n",
    "\n",
    "    # Value Metric Evaluations\n",
    "    results[\"P/E_eval\"] = (\n",
    "        (results[\"forwardPE\"] < results[\"forwardPE_industry_median\"]) &\n",
    "        (results[\"forwardPE\"] < historical_data[\"price_50th_percentile\"])\n",
    "    )\n",
    "    results[\"P/FCF_eval\"] = (\n",
    "        (results[\"freeCashflow\"] > results[\"freeCashflow_industry_median\"]) &\n",
    "        (results[\"freeCashflow\"] > historical_data[\"price_median\"])\n",
    "    )\n",
    "    results[\"EV/EBITDA_eval\"] = (\n",
    "        (results[\"enterpriseValue\"] < results[\"enterpriseValue_industry_median\"]) &\n",
    "        (results[\"ebitda_growth\"] > 0)  # Positive EBITDA growth\n",
    "    )\n",
    "    results[\"PEG_eval\"] = results[\"forwardPE\"] / results[\"revenue_growth\"] < 1\n",
    "\n",
    "    # Quality Metric Evaluations\n",
    "    results[\"ROE_eval\"] = results[\"returnOnEquity\"] > 15\n",
    "    results[\"FCF_Yield_eval\"] = results[\"freeCashflow\"] > results[\"freeCashflow_industry_median\"]\n",
    "    results[\"EBITDA_Growth_eval\"] = results[\"ebitda_growth\"] > results[\"ebitda_growth\"].median()\n",
    "    results[\"Revenue_Stability_eval\"] = results[\"revenue_growth\"].notnull()  # Check for non-missing stable growth\n",
    "\n",
    "    # Composite Scoring\n",
    "    results[\"Value_Score\"] = results[[\"P/E_eval\", \"P/FCF_eval\", \"EV/EBITDA_eval\", \"PEG_eval\"]].sum(axis=1)\n",
    "    results[\"Quality_Score\"] = results[[\"ROE_eval\", \"FCF_Yield_eval\", \"EBITDA_Growth_eval\", \"Revenue_Stability_eval\"]].sum(axis=1)\n",
    "    results[\"Composite_Score\"] = 0.7 * results[\"Value_Score\"] + 0.3 * results[\"Quality_Score\"]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0abdb24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics based on methodology...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/47xk0xhs45d_pbycq_l48w540000gn/T/ipykernel_85661/2062617587.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  revenue_growth = revenue.pct_change().mean() * 100\n",
      "/var/folders/3n/47xk0xhs45d_pbycq_l48w540000gn/T/ipykernel_85661/2062617587.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ebitda_growth = ebitda.pct_change().mean() * 100\n"
     ]
    }
   ],
   "source": [
    "# Main Execution: Metric Calculation\n",
    "if __name__ == \"__main__\":\n",
    "    # Calculate metrics\n",
    "    evaluated_results = calculate_metrics(historical_data, fundamental_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b67f3bb3-0b98-40e6-b9c4-1d63d8ee489c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 100 Evaluated Metrics Summary:\n",
      "      Composite_Score  Value_Score  Quality_Score\n",
      "NOC               3.7            4              3\n",
      "LYB               3.7            4              3\n",
      "NRG               3.7            4              3\n",
      "PARA              3.7            4              3\n",
      "BBY               3.0            3              3\n",
      "...               ...          ...            ...\n",
      "CMI               2.3            2              3\n",
      "F                 2.3            2              3\n",
      "HCA               2.3            2              3\n",
      "ABBV              2.3            2              3\n",
      "UNP               2.3            2              3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Informaci√≥n de las Top 10 Acciones\n",
    "# Ordenar por 'Composite_Score' en orden descendente\n",
    "evaluated_results_sorted = evaluated_results.sort_values(by=\"Composite_Score\", ascending=False)\n",
    "\n",
    "# Guardar las primeras 10 filas en un nuevo DataFrame\n",
    "top_100_results = evaluated_results_sorted.head(100)\n",
    "\n",
    "# Mostrar los resultados ordenados\n",
    "print(\"\\nTop 100 Evaluated Metrics Summary:\")\n",
    "print(top_100_results[[\"Composite_Score\", \"Value_Score\", \"Quality_Score\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a73383-4f7d-4b29-8c41-f4172a04e0fe",
   "metadata": {},
   "source": [
    "### Market Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd6262",
   "metadata": {},
   "source": [
    "## IBKR Market Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb66cc59-5891-4194-a185-e07e699d0c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to IBKR...\n",
      "An error occurred while connecting to IBKR: This event loop is already running\n",
      "Disconnected from IBKR due to an error.\n"
     ]
    }
   ],
   "source": [
    "# Initialize IB client\n",
    "ib = IB()\n",
    "\n",
    "try:\n",
    "    # Connect to IBKR TWS/Gateway\n",
    "    print(\"Connecting to IBKR...\")\n",
    "    ib.connect(host=\"127.0.0.1\", port=7497, clientId=3)  # Synchronous connection\n",
    "    print(\"Successfully connected to IBKR.\")\n",
    "\n",
    "    # Set market data type to delayed (avoiding real-time data fees)\n",
    "    print(\"Setting market data type to delayed...\")\n",
    "    ib.reqMarketDataType(3)  # Synchronous call to set delayed data type\n",
    "    print(\"Market data type set to delayed.\")\n",
    "\n",
    "    # Connection remains open for further tasks\n",
    "    print(\"IBKR connection is active and ready for further operations.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while connecting to IBKR: {e}\")\n",
    "    # If there's an error, attempt to disconnect gracefully\n",
    "    try:\n",
    "        ib.disconnect()\n",
    "        print(\"Disconnected from IBKR due to an error.\")\n",
    "    except Exception as disconnect_error:\n",
    "        print(f\"Error during disconnection: {disconnect_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903acf4-ea0a-498f-88e0-616a6a3f0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "async def fetch_market_scanners(ib, stock_universe):\n",
    "    \"\"\"\n",
    "    Fetch market scanner data asynchronously for Top Gainers, Top Losers, and Unusual Volume.\n",
    "    \"\"\"\n",
    "    print(\"Fetching market scanner data...\")\n",
    "    scanner_results = {\n",
    "        \"Top Gainers\": [],\n",
    "        \"Top Losers\": [],\n",
    "        \"Unusual Volume\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Define scanner subscriptions for each category\n",
    "        scanner_subscriptions = {\n",
    "            \"Top Gainers\": ScannerSubscription(instrument=\"STK\", locationCode=\"STK.US.MAJOR\", scanCode=\"TOP_PERC_GAIN\"),\n",
    "            \"Top Losers\": ScannerSubscription(instrument=\"STK\", locationCode=\"STK.US.MAJOR\", scanCode=\"TOP_PERC_LOSE\"),\n",
    "            \"Unusual Volume\": ScannerSubscription(instrument=\"STK\", locationCode=\"STK.US.MAJOR\", scanCode=\"HOT_BY_VOLUME\")\n",
    "        }\n",
    "        \n",
    "        # Fetch data for each scanner category\n",
    "        for category, subscription in scanner_subscriptions.items():\n",
    "            print(f\"Fetching {category} asynchronously...\")\n",
    "            scan_results = await ib.reqScannerSubscriptionAsync(subscription)\n",
    "            \n",
    "            # Filter results to only include symbols from the stock universe\n",
    "            scanner_results[category] = [\n",
    "                result.contract.symbol for result in scan_results if result.contract.symbol in stock_universe\n",
    "            ]\n",
    "            print(f\"{category} fetched successfully: {len(scanner_results[category])} stocks.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching market scanner data: {e}\")\n",
    "    \n",
    "    return scanner_results\n",
    "\n",
    "async def integrate_scanner_with_filtered(top_100_stocks, scanner_results):\n",
    "    \"\"\"\n",
    "    Map market scanner results to top 100 filtered stocks and assign Market Scanner Scores.\n",
    "    \"\"\"\n",
    "    print(\"Integrating scanner results with filtered stocks...\")\n",
    "    \n",
    "    # Initialize score columns\n",
    "    top_100_stocks[\"Market_Scanner_Score\"] = 0\n",
    "    \n",
    "    for index, row in top_100_stocks.iterrows():\n",
    "        symbol = index  # Assuming the stock symbol is the index\n",
    "        \n",
    "        # Assign scores based on scanner results\n",
    "        if symbol in scanner_results[\"Top Gainers\"]:\n",
    "            top_100_stocks.loc[index, \"Market_Scanner_Score\"] += 1\n",
    "        if symbol in scanner_results[\"Top Losers\"]:\n",
    "            top_100_stocks.loc[index, \"Market_Scanner_Score\"] -= 1\n",
    "        if symbol in scanner_results[\"Unusual Volume\"]:\n",
    "            top_100_stocks.loc[index, \"Market_Scanner_Score\"] += 1\n",
    "    \n",
    "    print(\"Integration completed.\")\n",
    "    return top_100_stocks\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main asynchronous execution to fetch scanner data and update the top 100 filtered stocks.\n",
    "    \"\"\"\n",
    "    # Ensure you have an active IBKR connection\n",
    "    print(\"Using active IBKR connection for Market Scanner...\")\n",
    "    \n",
    "    # Your existing 'evaluated_results_sorted' and 'top_100_results'\n",
    "    # Ensure `top_100_results` is loaded with your previously filtered top 100 stocks\n",
    "    top_100_stocks = top_100_results.copy()\n",
    "    stock_universe = top_100_stocks.index.tolist()  # Universe is the top 100 stock symbols\n",
    "    \n",
    "    # Fetch scanner data for the top 100 stocks\n",
    "    scanner_results = await fetch_market_scanners(ib, stock_universe)\n",
    "    \n",
    "    # Integrate scanner results with the filtered top 100 stocks\n",
    "    updated_top_100 = await integrate_scanner_with_filtered(top_100_stocks, scanner_results)\n",
    "    \n",
    "    # Display updated results with Market Scanner Score\n",
    "    print(\"\\nUpdated Top 100 with Market Scanner Score:\")\n",
    "    print(updated_top_100[[\"Composite_Score\", \"Market_Scanner_Score\"]].head())\n",
    "    \n",
    "    # Keep IBKR connection open for subsequent tasks\n",
    "    print(\"IBKR connection remains open for further operations.\")\n",
    "    return updated_top_100\n",
    "\n",
    "# Execution\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
